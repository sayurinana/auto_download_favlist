# AI_AGENT.md - 高性能系统项目规范守则

这是针对性能关键的Rust系统级应用开发的通用AI代理规范守则文档。

## 项目类型
高性能系统应用(High-Performance System Application)

## 性能目标
- 低延迟：P99延迟 < 1ms
- 高吞吐：支持10K+ QPS
- 内存效率：最小堆分配
- CPU效率：充分利用多核

## 核心要求

### 内存管理优化
- 避免频繁堆分配，使用对象池
- 零拷贝数据传输
- 内存布局优化，缓存友好访问
- 使用`#![no_std]`（如适用）

### 并发性能
- Lock-free数据结构优先
- 工作窃取算法应用
- NUMA感知调度
- 批处理减少系统调用

### 系统级优化
- 直接系统调用，减少中间层
- 内存映射I/O
- 异步I/O（io_uring/epoll）
- CPU亲和性设置

## 必需依赖
```toml
[dependencies]
# 高性能异步运行时
tokio = { version = "1.0", features = ["rt-multi-thread", "macros", "io-util", "net", "time"] }

# Lock-free数据结构
crossbeam = "0.8"
parking_lot = "0.12"    # 高性能锁

# 内存管理
bytes = "1.5"           # 高效字节缓冲区
smallvec = "1.11"       # 栈分配向量

# 性能分析
criterion = "0.5"       # 基准测试
```

## 推荐依赖
```toml
# SIMD优化
wide = "0.7"

# 高性能序列化
rmp-serde = "1.1"      # MessagePack
bincode = "1.3"        # 二进制序列化

# 系统级API
nix = "0.27"           # Unix系统调用
io-uring = "0.6"       # Linux异步I/O

# 内存池
bumpalo = "3.14"       # Bump分配器
slab = "0.4"           # Slab分配器

# 性能监控
pprof = "0.13"         # 性能分析
jemalloc = "0.5"       # 高性能内存分配器
```

## 系统配置
```toml
# 使用jemalloc作为全局分配器
[dependencies.jemallocator]
version = "0.5"

# 性能分析支持
[dependencies.pprof]
version = "0.13"
features = ["flamegraph", "protobuf-codec"]

# 内存分配器配置
[profile.release]
lto = "fat"                    # 完整链接时优化
codegen-units = 1              # 单个代码生成单元
panic = "abort"                # 避免展开开销
strip = true                   # 删除符号信息
opt-level = 3                  # 最高优化级别

[profile.bench]
lto = "fat"
codegen-units = 1
```

## 项目结构
```
src/
├── lib.rs                  # 库入口
├── main.rs                 # 应用入口
├── allocator.rs            # 自定义分配器
├── core/                   # 核心算法
│   ├── mod.rs
│   ├── processor.rs        # 主要处理逻辑
│   └── scheduler.rs        # 任务调度器
├── io/                     # I/O层
│   ├── mod.rs
│   ├── network.rs          # 网络I/O
│   └── disk.rs             # 磁盘I/O
├── memory/                 # 内存管理
│   ├── mod.rs
│   ├── pool.rs             # 对象池
│   └── arena.rs            # 内存竞技场
├── sync/                   # 同步原语
│   ├── mod.rs
│   ├── queue.rs            # 无锁队列
│   └── channel.rs          # 高性能通道
└── metrics/                # 性能监控
    ├── mod.rs
    └── collector.rs
```

## 代码模板

### 全局分配器配置
```rust
//! 高性能内存分配器配置

#[cfg(feature = "jemalloc")]
use jemallocator::Jemalloc;

#[cfg(feature = "jemalloc")]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;

// 或使用自定义分配器
use bumpalo::Bump;
use std::sync::Arc;

thread_local! {
    static BUMP: Arc<Bump> = Arc::new(Bump::new());
}

/// 快速分配函数
pub fn fast_alloc<T>(value: T) -> &'static T {
    BUMP.with(|bump| {
        bump.alloc(value)
    })
}
```

### Lock-Free队列
```rust
use crossbeam::queue::ArrayQueue;
use std::sync::Arc;

/// 高性能无锁队列
pub struct HighPerformanceQueue<T> {
    queue: Arc<ArrayQueue<T>>,
}

impl<T> HighPerformanceQueue<T> {
    pub fn new(capacity: usize) -> Self {
        Self {
            queue: Arc::new(ArrayQueue::new(capacity)),
        }
    }
    
    /// 非阻塞入队
    pub fn try_push(&self, item: T) -> Result<(), T> {
        self.queue.push(item)
    }
    
    /// 非阻塞出队
    pub fn try_pop(&self) -> Option<T> {
        self.queue.pop()
    }
    
    /// 批量操作以减少原子操作开销
    pub fn try_push_batch(&self, items: &mut Vec<T>) -> usize {
        let mut pushed = 0;
        while let Some(item) = items.pop() {
            if self.queue.push(item).is_ok() {
                pushed += 1;
            } else {
                items.push(item);
                break;
            }
        }
        pushed
    }
}
```

### 内存池实现
```rust
use slab::Slab;
use parking_lot::Mutex;

/// 对象池，避免频繁分配
pub struct ObjectPool<T> {
    pool: Mutex<Slab<T>>,
    factory: fn() -> T,
}

impl<T> ObjectPool<T> {
    pub fn new(factory: fn() -> T) -> Self {
        Self {
            pool: Mutex::new(Slab::new()),
            factory,
        }
    }
    
    /// 获取对象
    pub fn get(&self) -> PoolGuard<T> {
        let mut pool = self.pool.lock();
        let key = if pool.is_empty() {
            pool.insert((self.factory)())
        } else {
            pool.iter().next().unwrap().0
        };
        
        PoolGuard {
            pool: &self.pool,
            key,
        }
    }
}

/// 自动归还对象的守卫
pub struct PoolGuard<'a, T> {
    pool: &'a Mutex<Slab<T>>,
    key: usize,
}

impl<'a, T> std::ops::Deref for PoolGuard<'a, T> {
    type Target = T;
    
    fn deref(&self) -> &Self::Target {
        // SAFETY: 我们拥有这个key的独占访问权
        unsafe {
            &*self.pool.lock().get(self.key).unwrap() as *const T
        }
    }
}

impl<'a, T> Drop for PoolGuard<'a, T> {
    fn drop(&mut self) {
        // 对象会在drop时自动归还到池中
    }
}
```

### 零拷贝数据处理
```rust
use bytes::{Bytes, BytesMut, Buf, BufMut};
use std::io;

/// 零拷贝数据处理器
pub struct ZeroCopyProcessor {
    buffer: BytesMut,
}

impl ZeroCopyProcessor {
    pub fn new(capacity: usize) -> Self {
        Self {
            buffer: BytesMut::with_capacity(capacity),
        }
    }
    
    /// 处理数据而不进行拷贝
    pub fn process_data(&mut self, data: &[u8]) -> io::Result<Bytes> {
        // 直接操作原始数据，避免拷贝
        self.buffer.clear();
        self.buffer.extend_from_slice(data);
        
        // 就地处理数据
        self.transform_in_place();
        
        // 返回零拷贝视图
        Ok(self.buffer.split().freeze())
    }
    
    /// 就地数据转换
    fn transform_in_place(&mut self) {
        // 使用SIMD指令优化
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx2") {
                unsafe {
                    self.simd_transform();
                }
            } else {
                self.scalar_transform();
            }
        }
        
        #[cfg(not(target_arch = "x86_64"))]
        {
            self.scalar_transform();
        }
    }
    
    #[cfg(target_arch = "x86_64")]
    #[target_feature(enable = "avx2")]
    unsafe fn simd_transform(&mut self) {
        // SIMD优化的数据处理
        use std::arch::x86_64::*;
        
        let data = self.buffer.as_mut_ptr();
        let len = self.buffer.len();
        
        // 使用AVX2指令并行处理
        for i in (0..len).step_by(32) {
            if i + 32 <= len {
                let chunk = _mm256_loadu_si256(data.add(i) as *const __m256i);
                // 执行SIMD操作...
                let result = chunk; // 示例：实际会有复杂的变换
                _mm256_storeu_si256(data.add(i) as *mut __m256i, result);
            }
        }
    }
    
    fn scalar_transform(&mut self) {
        // 标量版本的数据处理
        for byte in self.buffer.iter_mut() {
            *byte = byte.wrapping_add(1); // 示例变换
        }
    }
}
```

### 性能监控
```rust
use std::time::{Duration, Instant};
use std::sync::atomic::{AtomicU64, Ordering};

/// 高性能指标收集器
pub struct MetricsCollector {
    // 使用原子操作避免锁竞争
    request_count: AtomicU64,
    total_latency_ns: AtomicU64,
    max_latency_ns: AtomicU64,
}

impl MetricsCollector {
    pub fn new() -> Self {
        Self {
            request_count: AtomicU64::new(0),
            total_latency_ns: AtomicU64::new(0),
            max_latency_ns: AtomicU64::new(0),
        }
    }
    
    /// 记录请求延迟
    pub fn record_latency(&self, latency: Duration) {
        let latency_ns = latency.as_nanos() as u64;
        
        self.request_count.fetch_add(1, Ordering::Relaxed);
        self.total_latency_ns.fetch_add(latency_ns, Ordering::Relaxed);
        
        // 更新最大延迟（使用比较交换避免竞争）
        let mut current_max = self.max_latency_ns.load(Ordering::Relaxed);
        while latency_ns > current_max {
            match self.max_latency_ns.compare_exchange_weak(
                current_max, 
                latency_ns, 
                Ordering::Relaxed, 
                Ordering::Relaxed
            ) {
                Ok(_) => break,
                Err(actual) => current_max = actual,
            }
        }
    }
    
    /// 获取统计信息
    pub fn get_stats(&self) -> MetricsStats {
        let count = self.request_count.load(Ordering::Relaxed);
        let total_ns = self.total_latency_ns.load(Ordering::Relaxed);
        let max_ns = self.max_latency_ns.load(Ordering::Relaxed);
        
        MetricsStats {
            request_count: count,
            avg_latency_ns: if count > 0 { total_ns / count } else { 0 },
            max_latency_ns: max_ns,
        }
    }
}

#[derive(Debug)]
pub struct MetricsStats {
    pub request_count: u64,
    pub avg_latency_ns: u64,
    pub max_latency_ns: u64,
}
```

### CPU亲和性设置
```rust
#[cfg(target_os = "linux")]
use nix::sched::{sched_setaffinity, CpuSet};
#[cfg(target_os = "linux")]
use nix::unistd::Pid;

/// CPU亲和性管理
pub struct CpuAffinityManager;

impl CpuAffinityManager {
    /// 将当前线程绑定到指定CPU核心
    #[cfg(target_os = "linux")]
    pub fn bind_to_cpu(cpu_id: usize) -> Result<(), nix::Error> {
        let mut cpu_set = CpuSet::new();
        cpu_set.set(cpu_id)?;
        sched_setaffinity(Pid::from_raw(0), &cpu_set)
    }
    
    /// 获取CPU核心数量
    pub fn cpu_count() -> usize {
        num_cpus::get()
    }
    
    /// 为工作线程分配CPU核心
    pub fn distribute_workers(worker_count: usize) -> Vec<usize> {
        let cpu_count = Self::cpu_count();
        (0..worker_count)
            .map(|i| i % cpu_count)
            .collect()
    }
}
```

## 基准测试
```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn benchmark_zero_copy_processing(c: &mut Criterion) {
    let mut group = c.benchmark_group("zero_copy");
    
    for size in [1024, 4096, 16384, 65536].iter() {
        group.bench_with_input(
            BenchmarkId::new("process", size), 
            size, 
            |b, &size| {
                let mut processor = ZeroCopyProcessor::new(size * 2);
                let data = vec![0u8; size];
                
                b.iter(|| {
                    black_box(processor.process_data(black_box(&data)).unwrap())
                })
            }
        );
    }
    
    group.finish();
}

criterion_group!(benches, benchmark_zero_copy_processing);
criterion_main!(benches);
```

## 性能分析配置
- 使用`perf`进行CPU分析
- 使用`valgrind`进行内存分析  
- 使用`criterion`进行微基准测试
- 使用火焰图分析热点代码
- 监控系统级指标（CPU、内存、I/O）

## 部署优化
- NUMA感知部署
- 巨页内存配置
- CPU隔离设置
- 网络中断绑定
- 文件系统优化（如XFS）
