# 规范守则 - 数据科学与机器学习

## 项目类型
- 数据分析脚本、特征工程管道、传统机器学习、深度学习训练与推理服务
- 交付形态：Notebook原型→模块化包→批处理/流式推理服务

## 核心原则
### 1. 数据治理与版本管理
- 使用`pandas`/`polars`进行ETL时，遵循不可变数据理念：每步产出独立数据集并记录元数据。
- 采用`dvc`或`lakeFS`版本化原始数据、特征与模型，保证实验可追溯。
- 对敏感数据执行脱敏与访问控制，遵守所在区域隐私法规（GDPR/CCPA）。

### 2. 实验管理与可重复性
- 使用`MLflow`或`Weights & Biases`记录参数、指标、模型artifact，强制填写实验描述与责任人。
- 将Notebook转换为模块化Pipeline（如`prefect`、`airflow`），在CI中运行冒烟实验以验证可执行性。
- 固定随机种子、声明环境依赖（`conda-lock`/`poetry export`），并在README中记录硬件、库版本。

### 3. 模型训练与评估
- 遵循[scikit-learn Model Selection](https://scikit-learn.org/stable/model_selection.html)中的交叉验证与管道组合实践。
- 构建数据切片（按地区、时间、用户群）评估公平性与稳定性。
- 记录训练时长、资源使用、数据漂移指标，为后续容量规划提供依据。
## 管道与服务化建议
```
ml_project/
├── data/
│   ├── raw/
│   ├── interim/
│   └── processed/
├── notebooks/
├── src/
│   ├── features/
│   ├── models/
│   ├── evaluation/
│   └── serving/
├── pipelines/
│   └── training.py
├── mlruns/              # MLflow追踪目录
└── tests/
    ├── test_features.py
    └── test_evaluation.py
```
## 验证、部署与监控
- 单元测试：对特征工程函数使用`pytest`校验输入输出类型与缺失值处理。
- 统计测试：在CI中运行分布漂移检测（KS检验、PSI）与模型性能回归。
- 模型部署：采用`FastAPI`/`BentoML`封装推理服务，暴露批量与实时接口，并记录推理耗时。
- 监控：收集模型指标（准确率、延迟）、数据质量指标（缺失率、异常值）、业务指标（转化率等），告警阈值需与业务方共定。
- 建立回滚策略：模型性能跌出SLO时自动回滚至上一版本，并保留AB测试数据。

## 参考资料
- [scikit-learn Model Selection and Evaluation](https://scikit-learn.org/stable/model_selection.html) - 官方模型评估与选择指南。
- [MLflow: Managing the ML Lifecycle](https://mlflow.org/docs/latest/ml/) - MLflow官方生命周期管理实践。
- [Microsoft Learn: MLflow on Azure Databricks](https://learn.microsoft.com/en-us/azure/databricks/mlflow/) - 企业环境中使用MLflow的最佳实践与权限策略。
- [OpenTelemetry Python Instrumentation](https://opentelemetry.io/docs/languages/python/instrumentation/) - 为推理服务提供端到端监控。
- [PEP 8 - Style Guide for Python Code](https://peps.python.org/pep-0008/) - 数据处理与模型代码的统一风格基线。
